{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmo0uJu0_75R",
        "outputId": "3b82bf17-431e-4b08-844e-afc68d9dd6cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10NrO_YQ4vqeJ3uyp5A0z2GJjnJWenc4s\n",
            "To: /content/flower_photos.zip\n",
            "100% 230M/230M [00:01<00:00, 169MB/s]\n",
            "Archive:  flower_photos.zip\n",
            "replace flower_photos/train/sunflowers/15118243470_7e0a7f159c_n.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!gdown 10NrO_YQ4vqeJ3uyp5A0z2GJjnJWenc4s\n",
        "!unzip  flower_photos.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "eexv8MzZ_8oD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpzN6uBK_8rM",
        "outputId": "94897477-4b72-4c6f-bc9d-6d970f8003c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "means = [0.485, 0.456, 0.406]\n",
        "stds = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Transforms to be applied to Train-Test-Validation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(32),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(means, stds)])\n"
      ],
      "metadata": {
        "id": "U17tm5G8_8tz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, img_path):\n",
        "        self.img_path = img_path\n",
        "\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "        for i in os.listdir(self.img_path):\n",
        "            if os.path.isdir(self.img_path + \"/\" + i):\n",
        "                for j in os.listdir(self.img_path + \"/\" + i):\n",
        "                    self.data.append(self.img_path + \"/\" + i + \"/\" + j)\n",
        "                    self.label.append(str(i))\n",
        "        label_encoder = preprocessing.LabelEncoder()\n",
        "        self.label = label_encoder.fit_transform(self.label)\n",
        "        mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "        print(mapping)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.data[idx])\n",
        "        img = train_transforms(img)\n",
        "        label = self.label[idx]\n",
        "        label_tensor = torch.as_tensor(label, dtype=torch.long)\n",
        "        return {'im': img, 'labels': label_tensor}\n"
      ],
      "metadata": {
        "id": "Wj-qqmBS_8wh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "train_dataset = CustomImageDataset('/content/flower_photos/train')\n",
        "test_dataset = CustomImageDataset('/content/flower_photos/test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssXTXJ44_8zC",
        "outputId": "5752398d-4fb7-45b7-8fa6-897c3c941982"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}\n",
            "{'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=32,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=4,\n",
        "                                          shuffle=False)\n"
      ],
      "metadata": {
        "id": "b_OAMh8T_81x"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = Model().to(device)"
      ],
      "metadata": {
        "id": "CM999Il5_84k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "2LgSLFcOAkqG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(200):\n",
        "    running_loss=0\n",
        "    running_acc=0\n",
        "   \n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data['im'].to(device), data['labels'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        result = torch.argmax(outputs,dim=1)\n",
        "        running_loss+=loss.item()\n",
        "        running_acc+=torch.mean((result==labels).type(torch.float))\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "      train_loss=running_loss/len(train_loader)\n",
        "      train_acc=running_acc/len(train_loader)\n",
        "      print('epoch {}, loss {}'.format(epoch, train_loss))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I44X4VG5ArQl",
        "outputId": "ac886727-6d71-4bdc-b303-1b04005c98b6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, loss 2.2333874272870586\n",
            "epoch 10, loss 1.2663533075435742\n",
            "epoch 20, loss 1.1670920687752802\n",
            "epoch 30, loss 1.0714523668761726\n",
            "epoch 40, loss 0.9826546354336781\n",
            "epoch 50, loss 0.9577107075098399\n",
            "epoch 60, loss 0.9400485796971364\n",
            "epoch 70, loss 0.9074533318614101\n",
            "epoch 80, loss 0.8910749721097516\n",
            "epoch 90, loss 0.8418254739529377\n",
            "epoch 100, loss 0.8706301668205777\n",
            "epoch 110, loss 0.8441367122504089\n",
            "epoch 120, loss 0.8249531450035336\n",
            "epoch 130, loss 0.8267104663290419\n",
            "epoch 140, loss 0.8099122952233564\n",
            "epoch 150, loss 0.8196809554959202\n",
            "epoch 160, loss 0.7863693629299198\n",
            "epoch 170, loss 0.7858730758632626\n",
            "epoch 180, loss 0.7829949745723793\n",
            "epoch 190, loss 0.7615860058917655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  \n",
        "correct = 0\n",
        "total = 0\n",
        "for i, data in enumerate(test_loader):\n",
        "    inputs, labels = data['im'].to(device), data['labels'].to(device)\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "print('Test Accuracy of the model on the test images: %d %%' % (100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUXGRo3zArTT",
        "outputId": "e25cfcb6-0232-4f27-f1b8-e0d702fd6852"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 75 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9s2bn8E2ArWu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f_TD8QPS_9CA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZDFl9p_U_9E1"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}